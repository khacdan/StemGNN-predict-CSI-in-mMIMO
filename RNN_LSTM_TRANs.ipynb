{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb09c71b-700f-4e03-b41b-62a3df6c4c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9979, 12, 128)\n",
      "(9979, 9, 128)\n",
      "6985 1996 998\n",
      "6540416\n",
      "Epoch 1/1, Train Loss: 64.58522120574428\n",
      "Epoch 1/1, Validation Loss: 3573.181136842758\n",
      "Training completed.\n",
      "73.7006471157074\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv_layer = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(3, 3))\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add a channel dimension (channels=1) for the 2D CNN\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNN(nn.Module):    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class RNN(nn.Module):    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.output_layer(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.output_layer(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "class Trans(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(Trans, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.transformer = nn.Transformer(d_model=32, nhead=4, num_encoder_layers=num_layers)\n",
    "        self.fc = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.transformer(x, x)  # Self-attention\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def switch(mode, input_size, hidden_size, num_layers, output_size):\n",
    "    switch_dict = {\n",
    "        1: FNN,\n",
    "        2: RNN,\n",
    "        3: LSTM,\n",
    "        4: Trans\n",
    "    }\n",
    "    return switch_dict.get(mode)(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "kmph = 3\n",
    "hori = 9\n",
    "cr = 128\n",
    "mode = 2 # 1=fnn, 2=rnn, 3=lstm, 4=trans\n",
    "input_size = 10080#2400 #4960 #10080 #20320 #40800 \n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "output_size = cr*hori \n",
    "num_filters = 32\n",
    "kernel_size = 3\n",
    "pool_kernel_size = 2\n",
    "pool_stride = 2\n",
    "\n",
    "\n",
    "# Load data from CSV\n",
    "csv_file_path = f'dataset/Uma_{cr}_{kmph}.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "input_data = df.values \n",
    "target_data = input_data.copy()  \n",
    "input_windows = []\n",
    "target_windows = []\n",
    "window_size = 12\n",
    "\n",
    "for i in range(len(input_data) - window_size - hori):\n",
    "    input_windows.append(input_data[i:i+window_size])\n",
    "    target_windows.append(target_data[i+window_size:i+window_size+hori])\n",
    "    \n",
    "print(np.shape(input_windows))\n",
    "print(np.shape(target_windows))\n",
    "\n",
    "input_windows = torch.tensor(input_windows, dtype=torch.float)\n",
    "target_windows = torch.tensor(target_windows, dtype=torch.float)\n",
    "\n",
    "dataset = TensorDataset(input_windows, target_windows)\n",
    "\n",
    "train_ratio = 0.7\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 1 - train_ratio - valid_ratio\n",
    "train_size = int(train_ratio * len(input_windows))\n",
    "valid_size = int((train_ratio + valid_ratio) * len(input_windows)) - int(train_ratio * len(input_windows))\n",
    "test_size = len(input_windows) - int((train_ratio + valid_ratio) * len(input_windows))\n",
    "\n",
    "print(train_size, valid_size, test_size)\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cnn_2d_net = CNN2D().to(device)\n",
    "# lstm_net = LSTMNetwork(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "lstm_net = switch(mode, input_size, hidden_size, num_layers, output_size).to(device)\n",
    "print(sum(p.numel() for p in lstm_net.parameters() if p.requires_grad))\n",
    "# print(cnn_2d_net)\n",
    "# print(lstm_net)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(cnn_2d_net.parameters()) + list(lstm_net.parameters()), lr=0.0001)\n",
    "\n",
    "num_epochs = 1\n",
    "avg_loss_tran = np.zeros(100)\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_2d_net.train()\n",
    "    lstm_net.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    cnt = 0\n",
    "    for inp, targets in train_loader:\n",
    "        if cnt < 198:\n",
    "#             print(cnt)\n",
    "            cnt += 1\n",
    "            inp = inp.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output_2d = cnn_2d_net(inp)\n",
    "            output_lstm = lstm_net(output_2d)\n",
    "            output_lstm = torch.reshape(output_lstm, (32,hori,-1))\n",
    "#             print(output_lstm.size())\n",
    "            loss = (criterion(output_lstm, targets))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss_tran[epoch] = np.sqrt(total_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss_tran[epoch]}\")\n",
    "\n",
    "    # Validation loop\n",
    "    cnn_2d_net.eval()\n",
    "    lstm_net.eval()\n",
    "    total_time = 0.0\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0.0\n",
    "        cnt = 0\n",
    "        for inp, targets in valid_loader:\n",
    "            if cnt < 50:\n",
    "                cnt += 1\n",
    "                inp = inp.to(device)\n",
    "                targets = targets.to(device)\n",
    "#                 print(cnt)\n",
    "\n",
    "                start_time = time.time()\n",
    "                output_2d = cnn_2d_net(inp)\n",
    "                output_lstm = lstm_net(output_2d)\n",
    "                output_lstm = torch.reshape(output_lstm, (32,hori,-1))\n",
    "                val_loss = (criterion(output_lstm, targets))\n",
    "                end_time = time.time()\n",
    "                \n",
    "                total_time += end_time - start_time\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss}\")\n",
    "    avg_time = total_time * len(valid_loader)\n",
    "print(\"Training completed.\")\n",
    "print(avg_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "468c0b3a-47c0-4239-89d1-84d0b75bcb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.5852]\n"
     ]
    }
   ],
   "source": [
    "loss_values = [round(avg_loss_tran[epoch], 4) for epoch in range(num_epochs)]\n",
    "print(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c9a6463-8dfa-4d9a-957c-8c0611f0f101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "1\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "targets torch.Size([32, 9, 128])\n",
      "prediction torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "torch.Size([32, 9, 128])\n",
      "Root Mean Squared Error (RMSE): 63.05992937088013\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the test_dataset from the previous code\n",
    "\n",
    "# Create DataLoader for the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Test loop\n",
    "cnn_2d_net.eval()\n",
    "lstm_net.eval()\n",
    "#mode = 'trans'\n",
    "mse_criterion = nn.MSELoss()\n",
    "total_mse = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    for inp, targets in test_loader:\n",
    "        if cnt < 30:\n",
    "            cnt += 1\n",
    "            inp = inp.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Pass data sequentially through the networks\n",
    "            output_2d = cnn_2d_net(inp)\n",
    "            output_lstm = lstm_net(output_2d)\n",
    "            output_lstm = torch.reshape(output_lstm, (32,hori,-1))\n",
    "#             print(cnt)\n",
    "            mse_loss = torch.sqrt(mse_criterion(output_lstm, targets))\n",
    "            total_mse += mse_loss.item()\n",
    "            print(\"targets\", targets.size())\n",
    "            print(\"prediction\", output_lstm.size())\n",
    "            \n",
    "            target = targets.to('cpu')\n",
    "            predict = output_lstm.to('cpu')\n",
    "            print(target.size())\n",
    "#             torch.save(predict[:,:,:],\"predict_rnn_5120.pt\")\n",
    "#             torch.save(target[:,:,:],\"target_rnn_5120.pt\")\n",
    "            print(predict.size())\n",
    "#             print(cnt)\n",
    "            if cnt == 1:\n",
    "                print(cnt)\n",
    "                torch.save(predict[:,:,:],f\"D:/CMa/{cr}/predict_{mode}_{cr}_3_{hori}.pt\")\n",
    "                torch.save(target[:,:,:],f\"D:/CMa/{cr}/target_{mode}_{cr}_3_{hori}.pt\")\n",
    "\n",
    "avg_mse = total_mse / len(test_loader)\n",
    "print(f\"Root Mean Squared Error (RMSE): {avg_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d7a13-a925-4644-8c75-371439b821c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
